{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (datasets, model_selection, pipeline, feature_extraction, naive_bayes, metrics, decomposition, \n",
    "                     preprocessing)\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded. \n",
      " Classes = ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "19997\n"
     ]
    }
   ],
   "source": [
    "data_location = '20_newsgroups'\n",
    "\n",
    "newsgroup_data = datasets.load_files(data_location, shuffle = True, random_state=42, encoding = 'ISO-8859-1')\n",
    "\n",
    "print('Data Loaded. \\n Classes = {classes}\\n{datapoints}'.format(\n",
    "    classes = newsgroup_data.target_names,\n",
    "    datapoints = len(newsgroup_data.data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newsgroups: rec.sport.hockey\n",
      "Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!zaphod.mps.ohio-state.edu!uwm.edu!cs.utexas.edu!utnut!alchemy.chem.utoronto.ca!golchowy\n",
      "From: golchowy@alchemy.chem.utoronto.ca (Gerald Olchowy)\n",
      "Subject: Re: RUMOUR - Keenan signs with Rangers?\n",
      "Message-ID: <1993Apr16.222232.17393@alchemy.chem.utoronto.ca>\n",
      "Organization: University of Toronto Chemistry Department\n",
      "References: <1993Apr16.171347.784@news.columbia.edu> <1993Apr16.183110.838@alchemy.chem.utoronto.ca> <1993Apr16.185823.6310@news.columbia.edu>\n",
      "Date: Fri, 16 Apr 1993 22:22:32 GMT\n",
      "Lines: 25\n",
      "\n",
      "In article <1993Apr16.185823.6310@news.columbia.edu> gld@cunixb.cc.columbia.edu (Gary L Dare) writes:\n",
      ">\n",
      ">Interestingly, Keenan's co-coach (or is it his \"Number One\"?) on Team\n",
      ">Canada at the World Championships is Roger Neilsen.  \n",
      ">\n",
      "\n",
      "But ultimately their hockey philosophies are like night and day...\n",
      "Keenan believes in pressuring the opposition and taking the\n",
      "initiative (within the limits of his system)...while Roger\n",
      "has a reactive hockey philosophy...which is why Messier will\n",
      "be able to and has played for Keenan, but thought Roger's way\n",
      "was a sure loser.\n",
      "\n",
      ">It'd be interesting if the Rangers call in the balance of Neilsen's\n",
      ">contract to be Keenan's assistant ...  Roger did do a very good job\n",
      ">with the mediocre players, just as he handled the Cinderella Canucks\n",
      ">of 10 years ago ... but his mistake was playing the Rangers like those\n",
      ">Canucks last May ...\n",
      ">\n",
      "\n",
      "Roger is a great assistant coach...but considering what must be bad\n",
      "blood between Nielson and Messier, it would be a mistake to bring\n",
      "him back even in that role.\n",
      "\n",
      "Gerald\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroup_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    newsgroup_data.data, newsgroup_data.target, test_size = 0.33, random_state=42)\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexf\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model acurracy is 0.9006060606060606\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.Pipeline([\n",
    "    ('counts',feature_extraction.text.CountVectorizer(\n",
    "        lowercase = True,\n",
    "        tokenizer = nltk.word_tokenize,\n",
    "        min_df = 2,\n",
    "        ngram_range = (1,2),\n",
    "        stop_words = stop_words\n",
    "    )),\n",
    "    ('tfidf', feature_extraction.text.TfidfTransformer()),\n",
    "    ('SVD',)\n",
    "    ('naivebayes', naive_bayes.MultinomialNB())\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('The model acurracy is {}'.format(\n",
    "    model.score(X_test,y_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.77      0.88      0.82       333\n",
      "           comp.graphics       0.88      0.86      0.87       332\n",
      " comp.os.ms-windows.misc       0.91      0.86      0.88       342\n",
      "comp.sys.ibm.pc.hardware       0.91      0.88      0.89       341\n",
      "   comp.sys.mac.hardware       0.93      0.94      0.94       318\n",
      "          comp.windows.x       0.89      0.94      0.92       332\n",
      "            misc.forsale       0.92      0.87      0.89       358\n",
      "               rec.autos       0.94      0.94      0.94       317\n",
      "         rec.motorcycles       0.97      0.97      0.97       320\n",
      "      rec.sport.baseball       0.98      0.96      0.97       337\n",
      "        rec.sport.hockey       0.90      0.97      0.93       310\n",
      "               sci.crypt       0.91      0.98      0.95       320\n",
      "         sci.electronics       0.92      0.90      0.91       321\n",
      "                 sci.med       0.98      0.93      0.96       340\n",
      "               sci.space       0.94      0.97      0.95       338\n",
      "  soc.religion.christian       0.89      1.00      0.94       324\n",
      "      talk.politics.guns       0.86      0.94      0.90       316\n",
      "   talk.politics.mideast       0.92      0.98      0.95       335\n",
      "      talk.politics.misc       0.83      0.76      0.80       331\n",
      "      talk.religion.misc       0.71      0.51      0.59       335\n",
      "\n",
      "               micro avg       0.90      0.90      0.90      6600\n",
      "               macro avg       0.90      0.90      0.90      6600\n",
      "            weighted avg       0.90      0.90      0.90      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,y_pred, target_names = newsgroup_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexf\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "c:\\users\\alexf\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([93.47737336, 86.62102596, 98.33804925, 78.87481618]), 'std_fit_time': array([ 9.05419857,  6.35574733, 14.82359451,  2.38281942]), 'mean_score_time': array([40.65827926, 37.53875963, 39.01107971, 29.10446676]), 'std_score_time': array([4.82631775, 6.10097347, 7.62689349, 1.81780371]), 'param_counts__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 2), (1, 2)],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_naivebayes__alpha': masked_array(data=[0.1, 3.0, 0.1, 3.0],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'counts__ngram_range': (1, 1), 'naivebayes__alpha': 0.1}, {'counts__ngram_range': (1, 1), 'naivebayes__alpha': 3.0}, {'counts__ngram_range': (1, 2), 'naivebayes__alpha': 0.1}, {'counts__ngram_range': (1, 2), 'naivebayes__alpha': 3.0}], 'split0_test_score': array([0.89020572, 0.86963327, 0.88662791, 0.87522361]), 'split1_test_score': array([0.89411238, 0.86433848, 0.89097829, 0.86702485]), 'split2_test_score': array([0.88896366, 0.86720502, 0.89143114, 0.87191566]), 'mean_test_score': array([0.89109502, 0.86705979, 0.88967679, 0.87138912]), 'std_test_score': array([0.00219348, 0.00216495, 0.00216608, 0.00336915]), 'rank_test_score': array([1, 4, 2, 3]), 'split0_train_score': array([0.9729972 , 0.93131653, 0.97535014, 0.9352381 ]), 'split1_train_score': array([0.97043673, 0.931243  , 0.97334826, 0.93930571]), 'split2_train_score': array([0.97124958, 0.92907484, 0.97471753, 0.93444457]), 'mean_train_score': array([0.97156117, 0.93054479, 0.97447198, 0.93632946]), 'std_train_score': array([0.00106827, 0.00103984, 0.0008355 , 0.00212932])}\n"
     ]
    }
   ],
   "source": [
    "grid_search_model = model_selection.GridSearchCV(\n",
    "    model,\n",
    "    {\n",
    "        'counts__ngram_range': [(1,1),(1,2)],\n",
    "        'naivebayes__alpha':(0.1,3.0)\n",
    "    },\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "grid_search_model.fit(X_train,y_train)\n",
    "print(grid_search_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=['i', 'me...f=False, use_idf=True)), ('naivebayes', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))])\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
